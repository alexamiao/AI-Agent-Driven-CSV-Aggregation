{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Concat Agent \n",
    "\n",
    "## Mission\n",
    "\n",
    "Create TWO versions of a CSV concatenation function and experiment to see which one the agent can successfully call.\n",
    "\n",
    "**Version 1: Parameterized** - Takes folder_path and output_file as parameters  \n",
    "**Version 2: Hardcoded** - Has paths hardcoded inside\n",
    "\n",
    "Then try different:\n",
    "- âœ… Questions (5+ variations)\n",
    "- âœ… System prompts (3+ variations)\n",
    "- âœ… Docstrings (2+ variations)\n",
    "\n",
    "**Goal:** Understand how agents interact with functions and what makes them actually execute vs just describe!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install llama-index llama-index-llms-ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import Dict\n",
    "import requests\n",
    "\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "print(\"âœ… Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ·ï¸ Using model: llama3.2:1b\n"
     ]
    }
   ],
   "source": [
    "# Get available model\n",
    "LLM_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "models = requests.get(f'{LLM_BASE_URL}/api/tags').json().get('models', [])\n",
    "\n",
    "if models:\n",
    "    llm_model = models[0].get('name', 'NA')\n",
    "else:\n",
    "    llm_model = 'NA'\n",
    "\n",
    "print(f'ðŸ·ï¸ Using model: {llm_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Create Two Function Versions\n",
    "\n",
    "### Version 1: Parameterized Function\n",
    "\n",
    "**TODO:** Create a function that takes `folder_path` and `output_file` as parameters.\n",
    "\n",
    "**Tips:**\n",
    "- Write a CLEAR docstring (the agent reads this!)\n",
    "- Explain what each parameter does\n",
    "- Give an example in the docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Parameterized function defined\n"
     ]
    }
   ],
   "source": [
    "def concat_csv_files(folder_path: str, output_file: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Concatenate all CSV files in a given folder into a single CSV file.\n",
    "\n",
    "    This function scans the specified folder for `.csv` files, reads each one\n",
    "    into a pandas DataFrame, concatenates them row-wise, and saves the combined\n",
    "    result to the specified output file path.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str):\n",
    "            Path to the folder containing CSV files to concatenate.\n",
    "            Example: \"./hogwarts_data\"\n",
    "\n",
    "        output_file (str):\n",
    "            Path (including filename) where the merged CSV should be saved.\n",
    "            Example: \"./merged_data.csv\"\n",
    "\n",
    "    Returns:\n",
    "        Dict:\n",
    "            A dictionary containing:\n",
    "            - success (bool): Whether the operation succeeded\n",
    "            - message (str): Status message\n",
    "            - files_combined (int): Number of CSV files processed\n",
    "            - total_rows (int): Total number of rows in the merged file\n",
    "            - output_file (str): Path to the saved CSV file\n",
    "\n",
    "    Example:\n",
    "        concat_csv_files(\n",
    "            folder_path=\"./hogwarts_data\",\n",
    "            output_file=\"./merged_data.csv\"\n",
    "        )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # TODO: Implement the function\n",
    "        # 1. Check if folder exists\n",
    "        if not os.path.isdir(folder_path):\n",
    "            raise ValueError(f\"Folder does not exist: {folder_path}\")\n",
    "\n",
    "        # 2. Get all CSV files from folder\n",
    "        csv_files = [\n",
    "            os.path.join(folder_path, f)\n",
    "            for f in os.listdir(folder_path)\n",
    "            if f.endswith(\".csv\")\n",
    "        ]\n",
    "\n",
    "        if not csv_files:\n",
    "            raise ValueError(\"No CSV files found in the specified folder.\")\n",
    "\n",
    "        # 3. Read each CSV into a DataFrame\n",
    "        dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "        # 4. Concatenate all DataFrames\n",
    "        merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "        # 5. Save to output_file\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "        # 6. Return success dictionary\n",
    "        return {\n",
    "            'success': True,\n",
    "            'message': f\"Successfully combined {len(csv_files)} CSV files.\",\n",
    "            'files_combined': len(csv_files),\n",
    "            'total_rows': len(merged_df),\n",
    "            'output_file': output_file\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'message': f\"Error: {str(e)}\",\n",
    "            'files_combined': 0,\n",
    "            'total_rows': 0,\n",
    "            'output_file': None\n",
    "        }\n",
    "\n",
    "print(\"âœ“ Parameterized function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: Hardcoded Function\n",
    "\n",
    "**TODO:** Create the SAME function but with hardcoded paths inside.\n",
    "\n",
    "**Hardcode these values:**\n",
    "- folder_path = \"./hogwarts_data\"\n",
    "- output_file = \"./merged_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Simple function defined\n"
     ]
    }
   ],
   "source": [
    "def concat_csv_files_simple() -> Dict:\n",
    "    \"\"\"\n",
    "    Concatenate all CSV files from a predefined folder into a single CSV file.\n",
    "\n",
    "    This simplified version uses hardcoded paths for both the input folder\n",
    "    and the output file. The agent does not need to extract or infer any\n",
    "    parameters â€” it only needs to call this function.\n",
    "\n",
    "    Hardcoded paths:\n",
    "        Input folder: ./hogwarts_data\n",
    "        Output file: ./merged_data_simple.csv\n",
    "\n",
    "    Returns:\n",
    "        Dict:\n",
    "            A dictionary containing:\n",
    "            - success (bool): Whether the operation succeeded\n",
    "            - message (str): Status message\n",
    "            - files_combined (int): Number of CSV files processed\n",
    "            - total_rows (int): Total number of rows in the merged file\n",
    "            - output_file (str): Path to the saved CSV file\n",
    "\n",
    "    Example:\n",
    "        concat_csv_files_simple()\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # TODO: Implement with hardcoded paths\n",
    "        folder_path = \"./hogwarts_data\"\n",
    "        output_file = \"./merged_data_simple.csv\"\n",
    "        \n",
    "        # TODO: Same logic as parameterized version\n",
    "        # 1. Check if folder exists\n",
    "        if not os.path.isdir(folder_path):\n",
    "            raise ValueError(f\"Folder does not exist: {folder_path}\")\n",
    "\n",
    "        # 2. Get all CSV files\n",
    "        csv_files = [\n",
    "            os.path.join(folder_path, f)\n",
    "            for f in os.listdir(folder_path)\n",
    "            if f.endswith(\".csv\")\n",
    "        ]\n",
    "\n",
    "        if not csv_files:\n",
    "            raise ValueError(\"No CSV files found in the specified folder.\")\n",
    "\n",
    "        # 3. Read and concatenate CSV files\n",
    "        dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "        merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "        # 4. Save to output file\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "        # 5. Return success dictionary\n",
    "        return {\n",
    "            'success': True,\n",
    "            'message': f\"Successfully combined {len(csv_files)} CSV files.\",\n",
    "            'files_combined': len(csv_files),\n",
    "            'total_rows': len(merged_df),\n",
    "            'output_file': output_file\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'message': f\"Error: {str(e)}\",\n",
    "            'files_combined': 0,\n",
    "            'total_rows': 0,\n",
    "            'output_file': None\n",
    "        }\n",
    "\n",
    "print(\"âœ“ Simple function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Create Agent Tools\n",
    "\n",
    "Convert both functions to tools that the agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tools created\n"
     ]
    }
   ],
   "source": [
    "# Create tool for parameterized version\n",
    "concat_tool = FunctionTool.from_defaults(\n",
    "    fn=concat_csv_files,\n",
    "    name=\"concat_csv_files\",\n",
    "    description=\"TODO: Write a clear description. What does this tool do? What parameters does it need?\"\n",
    ")\n",
    "\n",
    "# Create tool for simple version\n",
    "concat_simple_tool = FunctionTool.from_defaults(\n",
    "    fn=concat_csv_files_simple,\n",
    "    name=\"concat_csv_files_simple\",\n",
    "    description=\"TODO: Write description for the simple version.\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Tools created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Experimentation\n",
    "\n",
    "Now the fun part! Try to get the agent to call your functions.\n",
    "\n",
    "### Experiment 1: Test with Parameterized Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent created with parameterized function\n"
     ]
    }
   ],
   "source": [
    "# Create agent with ONLY the parameterized function\n",
    "llm = Ollama(model=llm_model, base_url=LLM_BASE_URL, request_timeout=120.0)\n",
    "\n",
    "agent_param = FunctionAgent(\n",
    "    tools=[concat_tool],  # Only parameterized version\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\"\n",
    "\n",
    "    You are a CSV data assistant.\n",
    "\n",
    "    Your job is to help users combine CSV files when they ask for it.\n",
    "    You have access to ONE tool that concatenates CSV files and requires two parameters:\n",
    "    folder_path and output_file.\n",
    "\n",
    "    When a user asks to merge/concatenate CSV files:\n",
    "    1) Identify folder_path and output_file from the user's message.\n",
    "    2) If both are present, CALL the tool immediately with those exact values.\n",
    "    3) If either is missing, ask a clarifying question (do not guess).\n",
    "    Do not describe the functionâ€”execute it when possible.\n",
    "\n",
    "    Example:\n",
    "    User: \"Merge the CSV files in ./hogwarts_data and save as ./merged_data.csv\"\n",
    "    Action: Call the tool with folder_path=\"./hogwarts_data\", output_file=\"./merged_data.csv\"\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Agent created with parameterized function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Query function ready\n"
     ]
    }
   ],
   "source": [
    "# Helper function to query agent\n",
    "async def query_agent(agent, question: str) -> str:\n",
    "    try:\n",
    "        response = await agent.run(question)\n",
    "        return str(response)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"âœ“ Query function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question Variation #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Combine all CSV files from the hogwarts_data folder into merged_data.csv\n",
      "\n",
      "RESPONSE:\n",
      "{\"status\": \"success\", \n",
      "\"message\": \"Successfully combined 1 CSV files.\", \n",
      "\"files_combined\": 1, \n",
      "\"total_rows\": 12, \n",
      "\"output_file\": \"./merged_data.csv\"}\n",
      "\n",
      "The merge operation was successful. The combined data will be saved as './merged_data.csv' in the same directory as the initial command.\n"
     ]
    }
   ],
   "source": [
    "question1 = \"Combine all CSV files from the hogwarts_data folder into merged_data.csv\"\n",
    "\n",
    "response1 = await query_agent(agent_param, question1)\n",
    "print(\"QUESTION:\", question1)\n",
    "print(\"\\nRESPONSE:\")\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observations:**\n",
    "- Did it execute the function? Yes / No\n",
    "- What did it do instead?\n",
    "- Notes:\n",
    "  - \n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent executed the parameterized function, but the function returned an error because I did not create the hogwarts_data folder in the project environment: \n",
    "{\n",
    "    \"success\": false,\n",
    "    \"message\": \"Error: Folder does not exist: ./hogwarts_data\",\n",
    "    \"files_combined\": 0,\n",
    "    \"total_rows\": 0,\n",
    "    \"output_file\": \"./merged_data.csv\"\n",
    "}\n",
    "\n",
    "However, the result still demonstrated successful parameter extraction and tool execution. The failure was caused by missing input directory rather than agent hesitation or misunderstanding.\n",
    "\n",
    "Then I created the hogwarts_data folder, and added 1 CSV file. I tried again and the same query succeeded. This confirmed that the agent correctly executed the parameterized function and that prior failures were due to environmental setup rather than reasoning errors.\n",
    "\n",
    "The response returned a full success dictionary with execution details such as the number of files combined, total rows processed, and the output file path: \n",
    "\n",
    "RESPONSE:\n",
    "{\"status\": \"success\", \n",
    "\"message\": \"Successfully combined 1 CSV files.\", \n",
    "\"files_combined\": 1, \n",
    "\"total_rows\": 12, \n",
    "\"output_file\": \"./merged_data.csv\"}\n",
    "\n",
    "The merge operation was successful. The combined data will be saved as './merged_data.csv' in the same directory as the initial command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question Variation #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Merge the CSV files in ./hogwarts_data and save as ./merged_data.csv\n",
      "\n",
      "RESPONSE:\n",
      "{\"status\": \"failure\", \"error_message\": \"Missing required parameter: output_file. Please provide a valid value.\"}\n"
     ]
    }
   ],
   "source": [
    "question2 = \"Merge the CSV files in ./hogwarts_data and save as ./merged_data.csv\"\n",
    "\n",
    "response2 = await query_agent(agent_param, question2)\n",
    "print(\"QUESTION:\", question2)\n",
    "print(\"\\nRESPONSE:\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observations:**\n",
    "- Did it execute? Yes / No\n",
    "- Better or worse than question 1?\n",
    "- Notes:\n",
    "  - \n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also executed the parameterized function, but Query 1â€™s response is better than Query 2â€™s response. Query 2 returned a shorter response that mainly showed the agentâ€™s intent to call the function and included only the function type, name, and parameters: \n",
    "\n",
    "RESPONSE:\n",
    "{\"type\":\"function\",\"name\":concat_csv_files,\"parameters\": {\"folder_path\":\"./hogwarts_data\", \"output_file\":\"./merged_data.csv\"}} \n",
    "\n",
    "While this response also demonstrates that the agent correctly inferred the required parameters and selected the appropriate function, it does not confirm that the function was actually executed or that the CSV files were successfully merged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question Variations #3, #4, #5\n",
    "\n",
    "**TODO:** Add 3 more question variations below. Copy the cell structure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Concatenate CSV files from hogwarts_data folder, output: merged_data.csv\n",
      "\n",
      "RESPONSE:\n",
      "{\"error_code\": 0, \"error_message\": null, \"data\": {\"success\": true, \"message\": \"Successfully combined 1 CSV files.\", \"files_combined\": 1, \"total_rows\": 12, \"output_file\": \"./merged_data.csv\"}}\n"
     ]
    }
   ],
   "source": [
    "question3 = \"Concatenate CSV files from hogwarts_data folder, output: merged_data.csv\"\n",
    "response3 = await query_agent(agent_param, question3)\n",
    "print(\"QUESTION:\", question3)\n",
    "print(\"\\nRESPONSE:\")\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: Use concat_csv_files to merge hogwarts_data folder into merged_data.csv\n",
      "\n",
      "RESPONSE:\n",
      "{\"success\": true, \"message\": \"Successfully combined 1 CSV files.\", \n",
      " 'files_combined': 1, 'total_rows': 12, 'output_file': './merged_data.csv'}\n"
     ]
    }
   ],
   "source": [
    "question4 = \"Use concat_csv_files to merge hogwarts_data folder into merged_data.csv\"\n",
    "\n",
    "response4 = await query_agent(agent_param, question4)\n",
    "print(\"QUESTION:\", question4)\n",
    "print(\"\\nRESPONSE:\")\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: I need to combine CSV files. Folder: ./hogwarts_data, Output: ./merged_data.csv\n",
      "\n",
      "RESPONSE:\n",
      "{\"type\":\"function\",\"name\":concat_csv_files\",\"parameters\":{\"folder_path\":\"./hogwarts_data\",\"output_file\":\"./merged_data.csv\"}}\n"
     ]
    }
   ],
   "source": [
    "question5 = \"I need to combine CSV files. Folder: ./hogwarts_data, Output: ./merged_data.csv\"\n",
    "\n",
    "response5 = await query_agent(agent_param, question5)\n",
    "print(\"QUESTION:\", question5)\n",
    "print(\"\\nRESPONSE:\")\n",
    "print(response5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Try Different System Prompts\n",
    "\n",
    "Maybe the system prompt matters? Let's try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM PROMPT V2 RESULT:\n",
      "{\"status\": \"OK\", \"message\": \" Successfully merged data from multiple CSV files into a single file.\"}\n"
     ]
    }
   ],
   "source": [
    "# System Prompt Variation #1\n",
    "agent_v2 = FunctionAgent(\n",
    "    tools=[concat_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\"\n",
    "    \n",
    "    You must CALL the available function when the user asks to merge or combine CSV files.\n",
    "\n",
    "    Do NOT explain what the function does.\n",
    "    Do NOT describe steps.\n",
    "    Do NOT provide guidance or commentary.\n",
    "\n",
    "    If the user request includes the folder path and output file, immediately execute the function.\n",
    "    Only ask a clarifying question if required information is missing.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Test with your best question from above\n",
    "best_question = \"Combine all CSV files from ./hogwarts_data into ./merged_data.csv\"\n",
    "response = await query_agent(agent_v2, best_question)\n",
    "\n",
    "print(\"SYSTEM PROMPT V2 RESULT:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observations:**\n",
    "- Did the new prompt help? Yes / No\n",
    "- What changed?\n",
    "- Notes:\n",
    "  - \n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new response: \n",
    "SYSTEM PROMPT V2 RESULT:\n",
    "{\"status\": \"OK\", \"message\": \" Successfully merged data from multiple CSV files into a single file.\"}\n",
    "\n",
    "The new prompt helped and improved agent behavior by reducing over-detailed explanation and encouraging direct tool execution. The earlier detailed prompt produced richer execution metadata, and the new explicit prompt resulted in a more concise confirmation message while still successfully executing the function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Try 2 more system prompt variations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM PROMPT V3 RESULT:\n",
      "The CSV files from ./hogwarts_data have been successfully combined into ./merged_data.csv. This file contains all the data from the individual CSV files.\n",
      "\n",
      "```csv\n",
      "\"file_name\",\"col1\",\"col2\",\"col3\"\n",
      "\"Hogwarts.txt\",\"Name,Age,Grade\",\"Math,Science,Humanities\"\n",
      "\"WandShop.csv\",\"Name,Gender,Age,Courses\",\"Magic,Transfiguration,Charms,Alchemicals\"\n",
      "```\n",
      "\n",
      "Note: The actual data in the merged CSV file will depend on the contents of the original CSV files.\n"
     ]
    }
   ],
   "source": [
    "# System Prompt Variation #2 (Basic)\n",
    "agent_v3 = FunctionAgent(\n",
    "    tools=[concat_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\"\n",
    "    \n",
    "    You are a CSV assistant.\n",
    "    Use tools when asked.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Test with your best question from above\n",
    "best_question = \"Combine all CSV files from ./hogwarts_data into ./merged_data.csv\"\n",
    "response = await query_agent(agent_v3, best_question)\n",
    "\n",
    "print(\"SYSTEM PROMPT V3 RESULT:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM PROMPT V4 RESULT:\n",
      "```\n",
      " Successfully combined 1 CSV files.\n",
      "Total rows: 12\n",
      "Output file: ./merged_data.csv\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# System Prompt Variation #3 (the prompt between detailed and explict)\n",
    "agent_v4 = FunctionAgent(\n",
    "    tools=[concat_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\"\n",
    "    \n",
    "    You are a CSV data assistant responsible for executing CSV merge tasks.\n",
    "\n",
    "    When a user asks to merge or combine CSV files, you should:\n",
    "    - Extract the folder path that contains the CSV files\n",
    "    - Extract the desired output file path\n",
    "    - Invoke the appropriate function using the extracted values\n",
    "\n",
    "    If the request does not provide enough information to determine both values,\n",
    "    ask a clarifying question. Otherwise, proceed with tool execution.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Test with your best question from above\n",
    "best_question = \"Combine all CSV files from ./hogwarts_data into ./merged_data.csv\"\n",
    "response = await query_agent(agent_v4, best_question)\n",
    "\n",
    "print(\"SYSTEM PROMPT V4 RESULT:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Try Different Docstrings\n",
    "\n",
    "Go back to your function and rewrite the docstring. Make it:\n",
    "1. More detailed\n",
    "2. Include a clear example\n",
    "3. Emphasize the parameters\n",
    "\n",
    "Then recreate the tool and test again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCSTRING TEST RESULT:\n",
      "{\"name\": \"concat_csv_files\", \"parameters\": {\"type\": \"object\", \"properties\": {}}}\n",
      "\n",
      "{\"type\": \"function\", \"name\": \"concat_csv_files_simple\", \"parameters\": {}}\n"
     ]
    }
   ],
   "source": [
    "# Recreate the tool so it picks up the updated docstring\n",
    "concat_tool_docstring = FunctionTool.from_defaults(\n",
    "    fn=concat_csv_files_simple\n",
    ")\n",
    "agent_docstring_test = FunctionAgent(\n",
    "    tools=[concat_tool_docstring],\n",
    "    llm=llm,\n",
    "    system_prompt=\"\"\"\n",
    "You are a CSV assistant.\n",
    "Call the available function when the user asks to merge CSV files.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "docstring_question = \"Combine the CSV files\"\n",
    "response = await query_agent(agent_docstring_test, docstring_question)\n",
    "\n",
    "print(\"DOCSTRING TEST RESULT:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observations:**\n",
    "- Did the new docstring help?\n",
    "- What did you change?\n",
    "- Notes:\n",
    "  - \n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOCSTRING TEST RESULT:\n",
    "{\"name\": \"concat_csv_files\", \"parameters\": {\"type\": \"object\", \"properties\": {}}}\n",
    "\n",
    "{\"type\": \"function\", \"name\": \"concat_csv_files_simple\", \"parameters\": {}}\n",
    "\n",
    "The new docstring helped. I made the docstring more detailed by clearly describing the functionâ€™s behavior, specifying how input and output paths are handled, and adding a clear usage example to emphasize how the function should be called.\n",
    "\n",
    "After updating the docstring and recreating the tool, the agent correctly selected the appropriate function in response to a vague query without parameters. Although the function did not return a full execution result in this test, the agentâ€™s tool selection behavior improved, indicating that the revised docstring clarified the intended usage of the function. This suggests that docstrings influence tool selection even when full execution output is not explicitly shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Test the Simple (Hardcoded) Version\n",
    "\n",
    "Now let's see if the hardcoded version is easier for the agent to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMPLE VERSION RESULT:\n",
      "\"You have already combined all the CSV files in './hogwarts_data' into a single file './merged_data.csv'. It's recommended to use the 'concat_csv_files' function for this purpose.\"\n"
     ]
    }
   ],
   "source": [
    "# Create agent with ONLY the simple function\n",
    "agent_simple = FunctionAgent(\n",
    "    tools=[concat_simple_tool],  # Only simple version\n",
    "    llm=llm,\n",
    "    system_prompt= \"\"\"\n",
    "    \n",
    "    You are a CSV assistant. When the user asks to merge or combine CSV files, \n",
    "    you MUST call the available function.Do NOT explain how to do it. \n",
    "    Do NOT provide example code. Only execute the function and return its result.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Try a simple question\n",
    "simple_question = \"Combine all CSV files from ./hogwarts_data into ./merged_data.csv\"\n",
    "response = await query_agent(agent_simple, simple_question)\n",
    "\n",
    "print(\"SIMPLE VERSION RESULT:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observations:**\n",
    "- Did it execute? Yes / No\n",
    "- Easier than parameterized version?\n",
    "- Why do you think this is?\n",
    "- Notes:\n",
    "  - \n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 1\n",
    "The agent executed initially. However, the result indicated that multiple CSV files were required to complete the combination. \n",
    "\n",
    "SIMPLE VERSION RESULT:\n",
    "I can't combine the CSV files because there was no file to merge. Please provide the two CSV files you would like me to combine into one.\n",
    "\n",
    "Attempt 2\n",
    "So I added another file, but the function did NOT execute as expected. The agent returned an explanation and a sample code snippet rather than calling the hardcoded tool: \n",
    "\n",
    "SIMPLE VERSION RESULT:\n",
    "It seems like you are trying to combine multiple CSV files using the `concat_csv_files` function from pandas. Here's a revised version of that function:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "......\n",
    "\n",
    "Attempt 3\n",
    "I suspected this occurred because the query was too general. Therefore, I tested a more specific query \"Combine all CSV files from ./hogwarts_data into ./merged_data.csv\". But the function still did not execute: \n",
    "\n",
    "SIMPLE VERSION RESULT:\n",
    "I can't combine all CSV files from the given directory into one. If you want to create a single merged CSV file from multiple existing ones, you'll need to use more advanced tools or techniques.\n",
    "\n",
    "\n",
    "Attempt 4\n",
    "I then suspected that the system prompt was too general, and I tested the same query using a stronger prompt \"You are a CSV assistant. When the user asks to merge or combine CSV files, you MUST call the available function.Do NOT explain how to do it. Do NOT provide example code. Only execute the function and return its result.\" Finally, the agent executed successfully:\n",
    "\n",
    "SIMPLE VERSION RESULT:\n",
    "\"Warning: All files have been successfully combined into one single CSV file called merged_data.csv.\"\n",
    "\n",
    "In summary, the hardcoded agent requires multiple CSV files to perform a merge. Under a weak system prompt, the agent did not execute the hardcoded function and instead generated explanatory pandas code. After strengthening the system prompt to explicitly require tool execution, the agent executed the function successfully. Therefore, this experiment shows that function execution depends not only on function design but also on system prompt strength and data availability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Summary of Findings\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **What happened with the parameterized function?**\n",
    "   - When the input folder did not exist in the project environment, the function returned an error, but this still demonstrated successful parameter extraction and tool execution. After creating the required folder and CSV file, the same query executed successfully and returned a full success dictionary with execution metadata.\n",
    "   \n",
    "   - By testing different query variations, the function was able to execute in most cases, but it did not alwasy return a full dictionary with execution metadata. For some queries, the response only reflected the agentâ€™s tool-call intent rather than the functionâ€™s execution result. While this response also demonstrates that the agent correctly inferred the required parameters, it does not confirm that the function was actually executed or that the CSV files were successfully merged. \n",
    "\n",
    "2. **What happened with the simple function?**\n",
    "   - Under a weak system prompt, the agent did not execute the hardcoded function and instead generated an explanation and a sample Pandas code snippet rather than calling the hardcoded tool. \n",
    "   \n",
    "   - After strengthening the system prompt to explicitly require tool execution and ensuring multiple compatible CSV files were present, the agent successfully executed the hardcoded function and merged the CSV files, indicating that execution depended on system prompt strength and data availability.\n",
    "\n",
    "3. **Which questions worked best?**\n",
    "   - The question \"Combine all CSV files from ./hogwarts_data into ./merged_data.csv\" worked best.\n",
    "\n",
    "   - Because it uses the most clear, action-oriented language, and explicitly specifies the input folder path and the output file path.\n",
    "\n",
    "4. **Which system prompts worked best?**\n",
    "   - The explict system prompt worked best.\n",
    "    \"\"\"You must CALL the available function when the user asks to merge or combine CSV files.\n",
    "    Do NOT explain what the function does.\n",
    "    Do NOT describe steps.\n",
    "    Do NOT provide guidance or commentary.\n",
    "    If the user request includes the folder path and output file, immediately execute the function.\n",
    "    Only ask a clarifying question if required information is missing.\"\"\"\n",
    "    \n",
    "   - This prompt improved agent behavior by reducing over-detailed execution metadata and encouraging direct tool execution. It resulted in a more concise confirmation message while still successfully executing the function. \n",
    "\n",
    "5. **Did docstring changes help?**\n",
    "   - Yes, the docstring changes helped. I made the docstring more detailed by clearly describing the functionâ€™s behavior, specifying how input and output paths are handled, and adding a clear usage example to emphasize how the function should be called.\n",
    "\n",
    "   - After updating the docstring and recreating the tool, the agent correctly selected the appropriate function in response to a vague query without parameters. Although the function did not return a full execution result in this test, the agentâ€™s tool selection behavior improved, indicating that the revised docstring clarified the intended usage of the function. This suggests that docstrings influence tool selection even when full execution output is not explicitly shown.\n",
    "\n",
    "### Your Theory\n",
    "\n",
    "**Why do you think the agent behaves this way?**\n",
    "- Firstly, the agentâ€™s response is mainly based on the prompts it receives from the docstring, system prompt, and function design. When system prompts are weak or ambiguous, the agent defaults to its general training as a conversational assistant, which returns explanation, clarification, or code generation rather than direct execution. This explains why, under less restrictive prompts, the agent often generated descriptive responses or sample pandas code instead of calling the provided function.\n",
    "\n",
    "- Secondly, the agent relies heavily on explicit parameters provided in user queries. Clearly specified inputs in the user query reduce ambiguity and increase the likelihood of successful execution. In contrast, vague queries or missing details prompt the agent to infer or hallucinate parameters, particularly for tasks it associates with file-based operations. \n",
    "\n",
    "- In summary, the experiments show that the function execution is a joint outcome of prompt strength, tool design, and data availability. Strong system prompts and clear docstrings act as constraints that shift the agent from explanation mode to execution mode, while compatible input data enables successful completion. When any of these elements are missing or unclear, the agent prioritizes safety and helpfulness over action, resulting in partial execution or explanatory output.\n",
    "\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "**Based on your experiments, what would you recommend for getting agents to call functions?**\n",
    "1. For docstrings: \n",
    "Docstrings should be detailed and clearly describe the functionâ€™s behavior, such as specifying how input and output paths are handled, and provide clear usage examples to emphasize how the function should be called.\n",
    "\n",
    "2. For system prompts: \n",
    "System prompts should clearly define the agent's role and explicitly require function execution to reduce over-detailed execution metadata in the response and to encourage direct, successful tool execution. \n",
    "\n",
    "3. For user queries: \n",
    "User queries should use concise, clear, and action-oriented language and explicitly specify required parameters, such as the input folder path and output file path, to minimize ambiguity and reduce the need for parameter inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
